### Sample size for positive and negative predictive value in diagnostic research
### using case-control designs
### http://biostatistics.oxfordjournals.org/content/10/1/94.full
library(bdpv)
# se =          # a (vector of) numeric value(s), specifying the expected sensitivity
# sp =          # a (vector of) numeric value(s), specifying the expected specificity
# prev =        # a (vector of) numeric value(s), specifying the prevalence
# NPV0 =        # a (vector of) numeric value(s), specifying the negative predictive value to be rejected under H0: NPV>=NPV0
# PPV0 =        # a (vector of) numeric value(s), specifying the positive predictive value to be rejected under H0: PPV>=PPV0
# NPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:NPV>=NPV0
# PPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:PPV>=PV0
# rangeP =      # a vector of two numeric values, giving the range of the proportion of truely positives to be considered in experimental design
# nsteps =      # a single (integer) value, the number of steps in rangeP to be considered
# alpha =       # a single numeric value, the type I error of the test (1-confidence level)
# setnames =    # an optional vector of names for the parameter sets
## Research the prevalence of the disease in the population
prev = 0.6 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.95
sp = 0.95
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.80   # sensitivity of current test to beat
currentSP = 0.80   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Amputation Heals     n1 = Amputation Does Not Heal",
ylab="Total sample size, (n0+n1)",
main="Diagnostic Clinical Performance Study \nSample Size Estimate")
### Sample size for positive and negative predictive value in diagnostic research
### using case-control designs
### http://biostatistics.oxfordjournals.org/content/10/1/94.full
library(bdpv)
# se =          # a (vector of) numeric value(s), specifying the expected sensitivity
# sp =          # a (vector of) numeric value(s), specifying the expected specificity
# prev =        # a (vector of) numeric value(s), specifying the prevalence
# NPV0 =        # a (vector of) numeric value(s), specifying the negative predictive value to be rejected under H0: NPV>=NPV0
# PPV0 =        # a (vector of) numeric value(s), specifying the positive predictive value to be rejected under H0: PPV>=PPV0
# NPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:NPV>=NPV0
# PPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:PPV>=PV0
# rangeP =      # a vector of two numeric values, giving the range of the proportion of truely positives to be considered in experimental design
# nsteps =      # a single (integer) value, the number of steps in rangeP to be considered
# alpha =       # a single numeric value, the type I error of the test (1-confidence level)
# setnames =    # an optional vector of names for the parameter sets
## Research the prevalence of the disease in the population
prev = 0.6 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.95
sp = 0.95
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.80   # sensitivity of current test to beat
currentSP = 0.80   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Amputation Heals     n1 = Amputation Does Not Heal",
ylab="Total sample size, (n0+n1)"
#main="Figure Pilot Study \nSample Size Estimate")
dev.copy(png, file = "SampleSizeEstimation.png", width=600, height=500)
dev.off()
### Sample size for positive and negative predictive value in diagnostic research
### using case-control designs
### http://biostatistics.oxfordjournals.org/content/10/1/94.full
library(bdpv)
# se =          # a (vector of) numeric value(s), specifying the expected sensitivity
# sp =          # a (vector of) numeric value(s), specifying the expected specificity
# prev =        # a (vector of) numeric value(s), specifying the prevalence
# NPV0 =        # a (vector of) numeric value(s), specifying the negative predictive value to be rejected under H0: NPV>=NPV0
# PPV0 =        # a (vector of) numeric value(s), specifying the positive predictive value to be rejected under H0: PPV>=PPV0
# NPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:NPV>=NPV0
# PPVpower =    # a (vector of) numeric value(s), the power that is to be obtained for the test H0:PPV>=PV0
# rangeP =      # a vector of two numeric values, giving the range of the proportion of truely positives to be considered in experimental design
# nsteps =      # a single (integer) value, the number of steps in rangeP to be considered
# alpha =       # a single numeric value, the type I error of the test (1-confidence level)
# setnames =    # an optional vector of names for the parameter sets
## Research the prevalence of the disease in the population
prev = 0.6 #PAD prevalence for age 55+ with risk factors
## Chosing the parameters for the desired results of our test
# se = seq(0.7, 1.0, 0.05)
# sp = seq(0.7, 1.0, 0.05)
se = 0.95
sp = 0.95
desiredPPV = (prev*se)/(prev*se+(1-prev)*(1-sp))
desiredNPV= ((1-prev)*sp)/(prev*(1-se)+(1-prev)*sp)
## Determine NPV0 and PPV0
currentSE = 0.80   # sensitivity of current test to beat
currentSP = 0.80   # specificity of current test to beat
## Positive and negative predictive values
PPV0 = (prev*currentSE)/(prev*currentSE+(1-prev)*(1-currentSP))
NPV0 = ((1-prev)*currentSP)/(prev*(1-currentSE)+(1-prev)*currentSP)
## Calculate Sample Size
result <- nPV(se, sp, prev, NPV0, PPV0,
NPVpower = 0.8, PPVpower = 0.8,
rangeP = c(0.05, 0.95), nsteps = 30,
alpha = 0.05, setnames = NULL)
print(result)
# outDAT a data.frame showing the parameter settings (in rows) and the input parameters se, sp, prev, NPV0, PPV0, NPVpower, PPVpower, trueNPV, truePPV
# nlist a list with an element for each parameter setting in OUTDAT, listing the results of nNPV, and nPPV
# NSETS a single (integer), the number of parameter sets
# nsteps a single (integer), the number of steps in the range of proportions of true positives
# rangeP the input range of the proportion of true positives
# propP the resulting sequence of proportions of true positives considere
## Plot Result
plotnPV(result, log = "y", NPVpar = list(col=3, lwd=2, lty=1),
PPVpar = list(col=4, lwd=2, lty=1),
xlab="Proportion of true positives in study cohort, n1/(n0+n1) \n n0 = Amputation Heals     n1 = Amputation Does Not Heal",
ylab="Total sample size, (n0+n1)")
#main="Figure Pilot Study \nSample Size Estimate")
dev.copy(png, file = "SampleSizeEstimation.png", width=600, height=500)
dev.off()
## Assignment 2
library(ggplot2)
library(dplyr)
library(tidyr)
library(grid)
(WD <- getwd())
if (!is.null(WD)) setwd(WD)
SCC <- readRDS("./ExploreData_Data/Source_Classification_Code.rds")
NEI <- readRDS("./ExploreData_Data/summarySCC_PM25.rds")
## 1 - Have total emissions from PM2.5 decreased in the United States from 1999
## to 2008? Using the base plotting system, make a plot showing the total PM2.5
## emission from all sources for each of the years 1999, 2002, 2005, and 2008.
DF1 <- NEI %>%
select(year, type, Emissions) %>%
group_by(type, year) %>%
summarize(PM25 = sum(Emissions))
model <- lm(PM25 ~ year, DF1)
with(DF1, plot(year, PM25, main = "Total PM2.5 From All Sources", type = "n"))
with(subset(DF1, type == "NON-ROAD"), points(year, PM25), col = "black", pch = 15)
with(subset(DF1, type == "NONPOINT"), points(year, PM25, col = "blue", pch = 16))
with(subset(DF1, type == "ON-ROAD"), points(year, PM25, col = "red", pch = 17))
with(subset(DF1, type == "POINT"), points(year, PM25, col = "green",pch = 18))
abline(model, lwd=2)
legend(x = 2006, y = 55, pch = c(15,16,17,18), col = c("black", "blue", "red", "green"),
legend = c("NON-ROAD", "NONPOINT", "ON-ROAD", "POINT"), cex = .75, bty= "n")
dev.copy(png, file = "plot1.png", width=500, height=350)
dev.off()
## 2 - Have total emissions from PM2.5 decreased in the Baltimore City, Maryland
## (fips == "24510") from 1999 to 2008? Use the base plotting system to make a
## plot answering this question.
DF2 <- NEI %>%
select(fips, year, Emissions) %>%
filter(fips == "24510") %>%
group_by(year) %>%
summarize(PM25 = sum(Emissions))
model <- lm(PM25 ~ year, DF2)
with(DF2, plot(year, PM25, pch = 15, main = "Average PM25 From All Emission Types \nin Baltimore, MD"))
abline(model, lwd = 1, col = "red")
legend(x=2005, y=10, pch = 15,bty = "n", col = c("black", "red"),
legend = c("Mean PM25", "Regression Line"))
dev.copy(png, file = "plot2.png", width=600, height=450)
dev.off()
## 3- Of the four types of sources indicated by the type (point, nonpoint,
## onroad, nonroad) variable, which of these four sources have seen decreases in
## emissions from 1999-2008 for Baltimore City? Which have seen increases in
## emissions from 1999-2008? Use the ggplot2 plotting system to make a plot
## answer this question.
DF3 <- NEI %>%
select(fips, year, type, Emissions) %>%
filter(fips == "24510") %>%
group_by(type, year) %>%
summarize(PM25 = sum(Emissions))
qplot(year, PM25, facets = . ~ type, data=DF3, main = "PM25 by Source Type in Baltimore, MD", geom = c("point", "smooth"), method = "lm") +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008)) +
theme(panel.margin = unit(1, "lines"))
dev.copy(png, file = "plot3.png", width=700, height=300)
dev.off()
## 4 - Across the United States, how have emissions from coal combustion-related
## sources changed from 1999-2008?
CoalCat <- SCC %>%
select(SCC, Short.Name) %>%
filter(grepl('Coal', Short.Name )) %>%
select(SCC)
NEIsub <- NEI %>%
select(year, SCC , Emissions) %>%
rename(PM25 = Emissions)
CoalMerged <- left_join(CoalCat, NEIsub, by = "SCC") #warnings; slow execution time
CoalMerged <- na.omit(CoalMerged)
DF4 <- CoalMerged %>%
group_by(year) %>%
summarize(PM25 = sum(PM25))
ggplot(DF4, aes(year, PM25)) + geom_point(size = 4, alpha = 0.5) +
geom_smooth(method = "lm") + labs(title = "Average Coal Emissions", x="Year", y=expression("Average Coal Emissions "* PM[2.5])) +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008))
dev.copy(png, file = "plot4.png", width=500, height=400)
dev.off()
## 5 - How have emissions from motor vehicle sources changed from 1999-2008 in
## Baltimore City?
VehicleCat <- SCC %>%
select(SCC, Short.Name) %>%
filter(grepl('Motor|Vehicle', Short.Name )) %>%
select(SCC)
NEIsub <- NEI %>%
select(fips, year, SCC , Emissions) %>%
rename(PM25 = Emissions) %>%
filter(fips == "24510")
VehicleMerged <- left_join(VehicleCat, NEIsub, by = "SCC")
VehicleMerged <- na.omit(VehicleMerged)
ggplot(VehicleMerged, aes(year, PM25)) +
geom_point(size = 4, alpha = 0.5) +
geom_smooth(method = "lm") +
labs(title = "Motor Vehicle Emissions in Baltimore, MD",x="Year", y=expression("Vehicle Emissions "* PM[2.5])) +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008))
dev.copy(png, file = "plot5.png", width=500, height=300)
dev.off()
## 6 - Compare emissions from motor vehicle sources in Baltimore City with
## emissions from motor vehicle sources in Los Angeles County, California
## (fips == "06037"). Which city has seen greater changes over time in motor
#  vehicle emissions?
NEIbaltimore <- NEI %>%
select(fips, year, SCC , Emissions) %>%
filter(fips == "24510") %>%
rename(PM25 = Emissions)
NEIla <- NEI %>%
select(fips, year, SCC, Emissions) %>%
filter(fips == "06037") %>%
rename(PM25 = Emissions)
Baltimore <- left_join(VehicleCat, NEIbaltimore, by = "SCC")
Baltimore <- na.omit(Baltimore)
LA <- left_join(VehicleCat, NEIla, by = "SCC")
LA <- na.omit(LA)
BLA <- bind_rows(Baltimore, LA)
BLA <- mutate(BLA, City = ifelse(fips == 24510, "Baltimore", "Los Angeles"))
BLA2 <- BLA %>%
group_by(year,fips) %>%
rename(City = fips) %>%
summarize(avePM25 = sum(PM25))
ggplot(BLA, aes(factor(year), log(PM25))) +
geom_boxplot(aes(color = City)) +
labs(title = "Motor Vehicle Emission Comparison of Two Cities",x="Year", y=expression("Vehicle Emissions log("* PM[2.5]*")"))
dev.copy(png, file = "plot6.png", width=500, height=300)
dev.off()
head(PM25)
head(DF1)
head(NEI)
DF1 <- NEI %>%
select(year == 1999)
DF1 <- NEI %>%
sort(year == 1999)
DF1 <- NEI %>%
filter(year == 1999)
length(DF1)
DF1 <- NEI %>%
filter(year == 2002)
length(DF1)
length(DF1[,1])
DF1 <- NEI %>%
filter(year == 1999)
length(DF1[,1])
DF1 <- NEI %>%
select(year, type, Emissions) %>%
group_by(type, year) %>%
summarize(PM25 = mean(Emissions))  # because the number of meters changes from year-to-year, the average is a better represnetation.  It controlls for the increase owing to the placement of new meeters.
model <- lm(PM25 ~ year, DF1)
DF1 <- NEI %>%
select(year, type, Emissions) %>%
group_by(type, year) %>%
summarize(PM25 = mean(Emissions))  # because the number of meters changes from year-to-year, the average is a better represnetation.  It controlls for the increase owing to the placement of new meeters.
model <- lm(PM25 ~ year, DF1)
with(DF1, plot(year, PM25, main = "Total PM2.5 From All Sources", type = "n"))
with(subset(DF1, type == "NON-ROAD"), points(year, PM25), col = "black", pch = 15)
with(subset(DF1, type == "NONPOINT"), points(year, PM25, col = "blue", pch = 16))
with(subset(DF1, type == "ON-ROAD"), points(year, PM25, col = "red", pch = 17))
with(subset(DF1, type == "POINT"), points(year, PM25, col = "green",pch = 18))
abline(model, lwd=2)
legend(x = 2006, y = 55, pch = c(15,16,17,18), col = c("black", "blue", "red", "green"),
legend = c("NON-ROAD", "NONPOINT", "ON-ROAD", "POINT"), cex = .75, bty= "n")
dev.copy(png, file = "plot1.png", width=500, height=350)
dev.off()
DF2 <- NEI %>%
select(fips, year, Emissions) %>%
filter(fips == "24510") %>%
filter(year == 1999)
length(DF[,1])
length(DF2[,1])
DF2 <- NEI %>%
select(fips, year, Emissions) %>%
filter(fips == "24510") %>%
filter(year == 2002)
length(DF2[,1])
DF2 <- NEI %>%
select(fips, year, Emissions) %>%
filter(fips == "24510") %>%
group_by(year) %>%
summarize(PM25 = mean(Emissions))
model <- lm(PM25 ~ year, DF2)
with(DF2, plot(year, PM25, pch = 15, main = "Average PM25 From All Emission Types \nin Baltimore, MD"))
abline(model, lwd = 1, col = "red")
legend(x=2005, y=10, pch = 15,bty = "n", col = c("black", "red"),
legend = c("Mean PM25", "Regression Line"))
dev.copy(png, file = "plot2.png", width=600, height=450)
dev.off()
DF3 <- NEI %>%
select(fips, year, type, Emissions) %>%
filter(fips == "24510") %>%
group_by(type, year) %>%
summarize(PM25 = mean(Emissions))
qplot(year, PM25, facets = . ~ type, data=DF3, main = "PM25 by Source Type in Baltimore, MD", geom = c("point", "smooth"), method = "lm") +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008)) +
theme(panel.margin = unit(1, "lines"))
dev.copy(png, file = "plot3.png", width=700, height=300)
dev.off()
ggplot(DF4, aes(year, PM25)) + geom_point(size = 4, alpha = 0.5) +
geom_smooth(method = "lm") + labs(title = "Average Coal Emissions", x="Year", y=expression("Average Coal Emissions "* PM[2.5])) +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008))
ggplot(VehicleMerged, aes(year, PM25)) +
geom_point(size = 4, alpha = 0.5) +
geom_smooth(method = "lm") +
labs(title = "Motor Vehicle Emissions in Baltimore, MD",x="Year", y=expression("Vehicle Emissions "* PM[2.5])) +
scale_x_continuous(breaks=c(1999, 2002, 2005, 2008))
ggplot(BLA, aes(factor(year), log(PM25))) +
geom_boxplot(aes(color = City)) +
labs(title = "Motor Vehicle Emission Comparison of Two Cities",x="Year", y=expression("Vehicle Emissions log("* PM[2.5]*")"))
install.packages("knitr")
datasets(airquality)
data(airquality)
head(airquality)
data(airquality)
g <- qplot(airquality, aes(ozone, Solar.R)) + geom_line()
library(ggplot2)
g <- qplot(airquality, aes(ozone, Solar.R)) + geom_line()
g
g <- qplot(airquality, aes(ozone, Solar.R))
g
with(airquality(plot(Ozone, Solar.R)))
plot(Ozone, Solar.R)
plot(Ozone ~ Solar.R, airquality)
library(stats)
regres = lm(Ozone ~ Solar.R, airquality)
abline(regress)
abline(regres)
First R Markdown
===============
Hey let's load some data
```{r}
data(airquality)
head(airquality)
```
What about a plot
```{r}
g <- plot(Ozone ~ Solar.R, airquality)
g
```
add a regression
```{r}
library(stats)
regres = lm(Ozone ~ Solar.R, airquality)
g + abline(regres)
```
First R Markdown
===============
Hey let's load some data
```{r}
data(airquality)
head(airquality)
```
What about a plot
```{r}
g <- plot(Ozone ~ Solar.R, airquality)
```
add a regression
```{r}
library(stats)
regres = lm(Ozone ~ Solar.R, airquality)
abline(regres)
```
data(airquality)
data(airquality)
head(airquality)
g <- plot(Ozone ~ Solar.R, airquality)
library(stats)
regres = lm(Ozone ~ Solar.R, airquality)
abline(regres)
library(stats)
regres = lm(Ozone ~ Solar.R, airquality)
plot(Ozone ~ Solar.R, airquality)
abline(regres)
library(stats)
model <- lm(Ozone ~ Solar.R, airquality)
with(airquality, plot(Ozone, Solar.R, pch = 15, main = "Airquality correlation to Solar Radiance"))
abline(model, lwd = 1, col = "red")
legend(x=2005, y=10, pch = 15,bty = "n", col = c("black", "red"),
legend = c("Mean PM25", "Regression Line"))
legend(x=50, y=150, pch = 15,bty = "n", col = c("black", "red"),
legend = c("Mean PM25", "Regression Line"))
```{r}
library(stats)
model <- lm(Ozone ~ Solar.R, airquality)
with(airquality, plot(Solar.R, Ozone, pch = 15, main = "Airquality correlation to Solar Radiance"))
abline(model, lwd = 1, col = "red")
legend(x=50, y=150, pch = 15,bty = "n", col = "red"),
legend = "Regression Line")
legend(x=50, y=150, pch = 15,bty = "n", col = "red",
legend = "Regression Line")
legend(x=25, y=200, pch = 15,bty = "n", col = "red",
legend = "Regression Line")
legend(x=25, y=175, pch = 15,bty = "n", col = "red",
legend = "Regression Line")
?plot
?legend
library(stats)
model <- lm(Ozone ~ Solar.R, airquality)
with(airquality, plot(Solar.R, Ozone, pch = 15, main = "Airquality correlation to Solar Radiance"))
abline(model, lwd = 1, col = "red")
legend(x=25, y=175, pch = 15,bty = "o", col = "red",
legend = "Regression Line")
library(stats)
model <- lm(Ozone ~ Solar.R, airquality)
with(airquality, plot(Solar.R, Ozone, pch = 15, main = "Airquality correlation to Solar Radiance"))
abline(model, lwd = 1, col = "red")
legend(x=25, y=160, pch = 15,bty = "o", col = "red",
legend = "Regression Line")
mcar(2,1)
par(mfrow=c(2,1))
plot(Ozone ~ Solar.R, airquality)
plot(Ozone ~ Month, airquality)
par(mfrow=c(2,1))
plot(Ozone ~ Solar.R, airquality)
plot(Ozone ~ Month, airquality)
**Hey** *let's load some data*
Add a regression
?legend
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/Reproducible_Research/RepData_PeerAssessment1")
activityDataFull <- read.table("C:/Users/jeffthatcher/Cloud Drive/RRepos/repdata-data-activity/activity.csv", sep = ",", header = TRUE)
activityData <- na.omit(activityDataFull)
meanDailySteps <- as.data.frame(as.matrix(tapply(activityData$steps, activityData$date, sum)))
colnames(meanDailySteps) <- c("Total_Steps_Per_Day")
library(ggplot2)
ggplot(meanDailySteps, aes(x=Total_Steps_Per_Day)) + geom_histogram(binwidth = 1000, fill = "sky blue", colour = "grey60", size=0.2)
meanSteps <- mean(na.omit(meanDailySteps$steps))
medianSteps <- median(na.omit(meanDailySteps$steps))
intervalSteps <- aggregate(activityData$steps, list(activityData$interval), mean)
colnames(intervalSteps) <- c("interval", "Average_Steps")
ggplot(intervalSteps, aes(interval, Average_Steps)) + geom_line()
mostSteps <- intervalSteps[which.max(intervalSteps$steps), ]
missingNAN<- is.na(activityDataFull$steps)
totalMissing <- sum(as.numeric(missingNAN))
for (i in 1:length(activityDataFull$steps)){
if (is.na(activityDataFull$steps[i] == TRUE)){
activityDataFull$steps[i] <- intervalSteps$Average_Steps[match(activityDataFull$interval[i], intervalSteps$interval)]
}
}
meanDailyStepsFull <- as.data.frame(as.matrix(tapply(activityDataFull$steps, activityDataFull$date, sum)))
colnames(meanDailyStepsFull) <- c("Total_Steps_Per_Day_Modified")
ggplot(meanDailyStepsFull, aes(x=Total_Steps_Per_Day_Modified)) + geom_histogram(binwidth = 1000, fill = "sky blue", colour = "grey60", size=0.2)
meanStepsFull <- mean(meanDailyStepsFull$steps_Modified)
medianStepsFull <- median(meanDailyStepsFull$steps_Modified)
DF <- merge(meanDailySteps, meanDailyStepsFull)
library(reshape2)
DF <- melt(DF)
colnames(DF) <- c("variable", "Total_Steps_Per_Day")
ggplot(DF, aes(x=Total_Steps_Per_Day)) + geom_histogram(binwidth = 1000, fill = "orange", colour = "grey60", size=0.2) + facet_grid(.~ variable)
#add the day-of-week column
activityDataFull$day <- weekdays(as.Date(activityDataFull$date), abbreviate=FALSE)
#convert day-of-week column vales to Weekday or Weekend
for (i in 1:length(activityDataFull$day)){
if (activityDataFull$day[i] == "Saturday" || activityDataFull$day[i] == "Sunday"){
activityDataFull$day[i] <- "Weekend"
} else {
activityDataFull$day[i] <- "Weekday"
}
}
# calculate the average interval steps for weekend and weekdays separetely and then combine.
activityDataWeekend <- subset(activityDataFull, day == "Weekend")
activityDataWeekday <- subset(activityDataFull, day == "Weekday")
activityIntervalStepsWeekend <- aggregate(activityDataWeekend$steps, list(activityDataWeekend$interval), mean)
colnames(activityIntervalStepsWeekend) <- c("interval", "Weekend_Steps")
activityIntervalStepsWeekday <- aggregate(activityDataWeekday$steps, list(activityDataWeekday$interval), mean)
colnames(activityIntervalStepsWeekday) <- c("interval", "Weekday_Steps")
DF2 <- merge(activityIntervalStepsWeekday, activityIntervalStepsWeekend)
DF2 <- melt(DF2, id = "interval")
# plot
colnames(DF2) <- c("interval", "variable", "Average_Steps")
ggplot(DF2, aes(interval,  Average_Steps)) + geom_line() + facet_grid(variable ~ .)
